{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import math\n",
    "\n",
    "import wandb\n",
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from src.linreg import LinregDataset\n",
    "from src.utils import save, set_seed\n",
    "from src.training import train, evaluate\n",
    "from src.transformer import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    n_dims:       int = 4\n",
    "    num_layers:   int = 1\n",
    "    attn_heads:   int | None = None\n",
    "    head_dim:     int | None = None\n",
    "    hidden_dim:   int | None = None\n",
    "    dhat:         int | None = None\n",
    "    mlp_hidden:   int = 128\n",
    "    context:      int = 129\n",
    "    method:       str = 'softmax'\n",
    "    activation:   nn.Module = nn.GELU\n",
    "    elu_alpha:    float = 1.0\n",
    "    \n",
    "    def _calculate_dhat(self):\n",
    "        if self.method in ['based', 'rebased']:\n",
    "            low = math.floor(math.sqrt(self.head_dim))\n",
    "            top = math.ceil(math.sqrt(self.head_dim))\n",
    "            lowdiff = math.fabs(self.hidden_dim - low ** 2 * self.attn_heads)\n",
    "            topdiff = math.fabs(self.hidden_dim - top ** 2 * self.attn_heads)\n",
    "            if lowdiff < topdiff:\n",
    "                dhat = low * self.attn_heads\n",
    "            else:\n",
    "                dhat = top * self.attn_heads\n",
    "        else:\n",
    "            dhat = self.hidden_dim\n",
    "        return dhat\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.hidden_dim is not None and self.attn_heads is not None:\n",
    "            self.head_dim = self.hidden_dim // self.attn_heads\n",
    "        elif self.attn_heads is not None and self.head_dim is not None:\n",
    "            self.hidden_dim = self.attn_heads * self.head_dim\n",
    "        else:\n",
    "            raise ValueError('You should provide either (hidden_dim, attn_heads) or (attn_heads, head_dim).')\n",
    "        \n",
    "        if self.dhat is None:\n",
    "            self.dhat = self._calculate_dhat()\n",
    "    \n",
    "def get_config(name, n_dims):\n",
    "    models = {\n",
    "        'softmax': (Config(\n",
    "            n_dims = n_dims, num_layers = 1,\n",
    "            attn_heads = 4, hidden_dim = 96,\n",
    "            mlp_hidden = 256, context = 257,\n",
    "            method = 'softmax',\n",
    "        ), 1e-3, 64, 32),\n",
    "        'based': (Config(\n",
    "            n_dims = n_dims, num_layers = 1,\n",
    "            attn_heads = 4, hidden_dim = 96,\n",
    "            mlp_hidden = 256, context = 257,\n",
    "            method = 'based'\n",
    "        ), 1e-3, 64, 32),\n",
    "        'rebased': (Config(\n",
    "            n_dims = n_dims, num_layers = 1,\n",
    "            attn_heads = 4, hidden_dim = 96,\n",
    "            mlp_hidden = 256, context = 257,\n",
    "            method = 'rebased'\n",
    "        ), 1e-3, 64, 32),\n",
    "        'learnable': (Config(\n",
    "            n_dims = n_dims, num_layers = 1,\n",
    "            attn_heads = 4, hidden_dim = 96,\n",
    "            mlp_hidden = 256, context = 257,\n",
    "            method = 'learnable'\n",
    "        ), 1e-3, 64, 32),\n",
    "        'elu': (Config(\n",
    "            n_dims = n_dims, num_layers = 1,\n",
    "            attn_heads = 4, hidden_dim = 96,\n",
    "            mlp_hidden = 256, context = 257,\n",
    "            method = 'learnable'\n",
    "        ), 1e-3, 64, 32),\n",
    "        'squared': (Config(\n",
    "            n_dims = n_dims, num_layers = 1,\n",
    "            attn_heads = 4, hidden_dim = 96,\n",
    "            mlp_hidden = 256, context = 257,\n",
    "            method = 'learnable'\n",
    "        ), 1e-3, 64, 32),\n",
    "    }\n",
    "    return models[name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тренировка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax_1_42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc1f3798e65b42188ad8b6b863a99c0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b = 1 --- loss = 1.10198\n",
      "b = 5 --- loss = 1.60882\n",
      "b = 10 --- loss = 3.98357\n",
      "b = 15 --- loss = 6.25741\n",
      "softmax_5_42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de95b442616147a79a41c63cae2f86f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b = 1 --- loss = 1.08826\n",
      "b = 5 --- loss = 1.13193\n",
      "b = 10 --- loss = 1.89257\n",
      "b = 15 --- loss = 2.42076\n",
      "based_1_42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3583a8fbc3840fcb6c90de9778bd95d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b = 1 --- loss = 1.05669\n",
      "b = 5 --- loss = 1.73280\n",
      "b = 10 --- loss = 2.97090\n",
      "b = 15 --- loss = 5.78900\n",
      "based_5_42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48a3ae9fa95e46268c812faaab5dfcda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b = 1 --- loss = 1.04130\n",
      "b = 5 --- loss = 1.11826\n",
      "b = 10 --- loss = 1.27768\n",
      "b = 15 --- loss = 1.99170\n",
      "rebased_1_42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50261851b29943c3910d0d4c8b2fb025",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b = 1 --- loss = 0.91004\n",
      "b = 5 --- loss = 1.49189\n",
      "b = 10 --- loss = 3.64890\n",
      "b = 15 --- loss = 7.27225\n",
      "rebased_5_42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "871049112d0849a3b73f4a8a44ac30fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b = 1 --- loss = 0.85395\n",
      "b = 5 --- loss = 1.02606\n",
      "b = 10 --- loss = 1.46918\n",
      "b = 15 --- loss = 2.28624\n",
      "learnable_1_42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d526c7ab6e134f7ca37a992a2155689e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b = 1 --- loss = 0.93074\n",
      "b = 5 --- loss = 1.29131\n",
      "b = 10 --- loss = 1.87351\n",
      "b = 15 --- loss = 3.07824\n",
      "learnable_5_42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fdc21f4b5af4fd19ce912e7c11fcde0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b = 1 --- loss = 0.93117\n",
      "b = 5 --- loss = 1.24895\n",
      "b = 10 --- loss = 1.78055\n",
      "b = 15 --- loss = 2.87314\n",
      "elu_1_42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e32f6a1640af4e4e80b774cad829d712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b = 1 --- loss = 0.93074\n",
      "b = 5 --- loss = 1.29131\n",
      "b = 10 --- loss = 1.87351\n",
      "b = 15 --- loss = 3.07824\n",
      "elu_5_42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbce04d175194d4fa807fe177e0234d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b = 1 --- loss = 0.93117\n",
      "b = 5 --- loss = 1.24895\n",
      "b = 10 --- loss = 1.78055\n",
      "b = 15 --- loss = 2.87314\n",
      "squared_1_42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "772cc32de7df4363bb490b1b6d43b9b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b = 1 --- loss = 0.93074\n",
      "b = 5 --- loss = 1.29131\n",
      "b = 10 --- loss = 1.87351\n",
      "b = 15 --- loss = 3.07824\n",
      "squared_5_42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d94f74e1d084057bcfdab8032b76174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b = 1 --- loss = 0.93117\n",
      "b = 5 --- loss = 1.24895\n",
      "b = 10 --- loss = 1.78055\n",
      "b = 15 --- loss = 2.87314\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "from itertools import product\n",
    "\n",
    "N = 4\n",
    "n_dims = 8\n",
    "mean, std = 0, 1\n",
    "\n",
    "seeds = [42, 451, 1984][:1]\n",
    "models = ['softmax', 'based', 'rebased', 'learnable', 'elu', 'squared']\n",
    "bs = [1, 5]\n",
    "\n",
    "runs = []\n",
    "for model, bs, seed in product(models, bs, seeds):\n",
    "    runs.append((model, bs, seed))\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "extrp_bs = [1, 5, 10, 15]\n",
    "\n",
    "for (name, b, seed) in runs:\n",
    "\n",
    "    config, lr, train_bsize, test_bsize = get_config(name, n_dims)\n",
    "    if config.context != N * 2 + 1:\n",
    "        config.context = N * 2 + 1\n",
    "\n",
    "    train_loader = DataLoader(LinregDataset(\n",
    "        n_dims = n_dims, n_points = N + 1,\n",
    "        xmean = mean, xstd = std, device = device\n",
    "    ), batch_size = 1)\n",
    "    test_loader = DataLoader(LinregDataset(\n",
    "        n_dims = n_dims, n_points = N + 1,\n",
    "        xmean = mean, xstd = std, device = device,\n",
    "        total = test_bsize * 5\n",
    "    ), batch_size = 1)\n",
    "\n",
    "    set_seed(seed)\n",
    "\n",
    "    model = Transformer(config).to(device)\n",
    "    optimizer = AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "    run_name = f'{name}_{b}_{seed}'\n",
    "    print(run_name)\n",
    "    # run = wandb.init(\n",
    "    #     project = 'Linear Transformer',\n",
    "    #     name = run_name,\n",
    "    #     config = {\n",
    "    #         'name': f'{name}_{b}',\n",
    "    #         'model': name,\n",
    "    #         'b': b,\n",
    "    #         'train batch size': train_bsize,\n",
    "    #         'test batch size': test_bsize,\n",
    "    #         'lr': lr,\n",
    "    #         'seed': seed,\n",
    "    #         'N': N,\n",
    "    #     }\n",
    "    # )\n",
    "\n",
    "    loss_history, eval_history = train(\n",
    "        model, train_loader, test_loader, optimizer, \n",
    "        steps = 75, b = b, run = None, log_every = 1\n",
    "    )\n",
    "\n",
    "    extrapolation = []\n",
    "    for bi in extrp_bs:\n",
    "        result = evaluate(test_loader, model, bi)\n",
    "        extrapolation.append(result)\n",
    "        print(f'b = {bi} --- loss = {result:.5f}')\n",
    "        # run.log({'b': bi, 'MSE': result})\n",
    "    \n",
    "    # run.finish()\n",
    "\n",
    "    save(\n",
    "        name = run_name, \n",
    "        model = model,\n",
    "        loss = loss_history, \n",
    "        eval = eval_history, \n",
    "        extr = extrapolation,\n",
    "        path = './results/'\n",
    "    )\n",
    "\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Валидация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from itertools import product\n",
    "\n",
    "n_dims = 8\n",
    "mean, std = 0, 1\n",
    "\n",
    "seeds = [42, 451, 1984]\n",
    "models = ['medium', 'small', 'tiny']\n",
    "bs = [15, 10, 5, 1]\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "runs = []\n",
    "for model, b in product(models, bs):\n",
    "    runs.append((model, b))\n",
    "    \n",
    "test_seed = 4815163242 % 2**31\n",
    "num_launches = 10\n",
    "    \n",
    "results = {}\n",
    "pbar = tqdm(range(len(runs) * num_launches * len(seeds)))\n",
    "for (name, b) in runs:\n",
    "    config, lr, train_bsize, test_bsize = get_config(name, n_dims)\n",
    "    n_points = (config.context + 1) // 2\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    set_seed(test_seed)\n",
    "    for seed in seeds:\n",
    "        model = torch.load(f'./results/experiment 1/models/{name}_{b}_{seed}.pt')\n",
    "            \n",
    "        for i in range(num_launches):\n",
    "            \n",
    "            std = torch.rand((1,)).item() * 2\n",
    "            loader = DataLoader(LinregDataset(\n",
    "                n_dims = n_dims, n_points = n_points,\n",
    "                mean = mean, std = std, random = True,\n",
    "                total = 128 * 10, device = device\n",
    "            ), batch_size = 128)\n",
    "            \n",
    "            total = 0\n",
    "            with torch.no_grad():\n",
    "                for (x, y) in loader:\n",
    "                    \n",
    "                    preds = model(x[:, :-1], b)\n",
    "                    preds = torch.stack(preds)\n",
    "                    targs = torch.stack([y] * b)\n",
    "                    \n",
    "                    loss = (targs[:,:,-1] - preds[:,:,-1]).square().mean(dim=0).mean()\n",
    "                    \n",
    "                    total += loss.item() / loader.dataset.n_dims\n",
    "            res.append(total / len(loader))\n",
    "            pbar.set_description(f'Run \\'{name}_{b}\\', seed {seed}...')\n",
    "            pbar.update(1)\n",
    "                \n",
    "    results[f'{name}_{b}'] = res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
